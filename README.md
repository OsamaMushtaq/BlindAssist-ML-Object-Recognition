ğŸ¦¯ BlindAssist
Machine Learning Enhanced Object Recognition, GPS Tracking, and Speech Feedback

Final Year Project (FYP)
Lahore Garrison University
Batch: 2024

ğŸ“Œ Project Overview

With over 284 million people globally affected by visual impairment, independent navigation remains a critical challenge. Most existing assistive technologies lack real-time intelligence, environment awareness, and integrated safety features, leaving visually impaired individuals vulnerable in dynamic environments.

BlindAssist is a hardwareâ€“software integrated assistive system that combines machine learningâ€“based object recognition, GPS-based navigation, and real-time speech feedback to enhance mobility, safety, and independence for visually impaired users.

â— Problem Statement

Existing assistive technologies for visually impaired individuals often fail to provide real-time assistance and comprehensive functionality, limiting their effectiveness in dynamic environments.
This lack of intelligent feedback and navigation support increases the risk of accidents and dependency.

The BlindAssist project addresses this gap by integrating machine learning, GPS tracking, and speech feedback into a single smart system. The goal is to empower visually impaired individuals, improve accessibility, and promote inclusivity through intelligent and affordable assistive technology.

ğŸ’¡ Solution Overview

BlindAssist operates as a smart assistive stick that continuously senses the surrounding environment and provides audio-based guidance to the user.

Core Features

Real-Time Obstacle Detection using ultrasonic sensors

Machine Learningâ€“Based Object Recognition via a camera module

GPS-Based Navigation Assistance for location awareness

Speech Feedback System for hands-free interaction

Emergency Alert Mechanism to notify caregivers or emergency contacts

âš™ï¸ System Evaluation & Results

The system was rigorously tested to validate its effectiveness across core functionalities.

ğŸ” Evaluation Results

Obstacle Detection
Ultrasonic sensors achieved high accuracy with an error margin of Â±1 cm, ensuring reliable real-time obstacle alerts.

Object Recognition
The machine learning model achieved an average recognition accuracy of 92%, enabling effective identification and avoidance of obstacles.

Navigation Assistance
The GPS module provided accurate location tracking within a 3-meter radius, supporting dependable wayfinding and route guidance.

Emergency Alerts
The GSM module successfully transmitted emergency alerts within 8 seconds, ensuring rapid notification to caregivers or emergency services.

These results demonstrate that BlindAssist effectively enhances navigation safety and situational awareness for visually impaired individuals.

ğŸ§  Technologies Used
Hardware

Smart Assistive Stick

Ultrasonic Sensors

Camera Module

GPS Module

GSM Module

Microcontroller / Embedded Platform

Audio Output (Speaker / Headphones)

Software & Tools

Machine Learning (Object Recognition Model)

Embedded Programming

Computer Vision

Text-to-Speech (TTS)

GPS & Communication Protocols

(Detailed specifications available in project documentation)

ğŸ“ Project Documentation

The following documents are available in the repository:

ğŸ“„ Software Requirements Specification (SRS)

ğŸ“„ Project Proposal

ğŸ“„ Final Project Report

ğŸ“„ Complete Technical Documentation

Refer to the /docs folder for full details.

ğŸš€ Future Enhancements

Integration of deep learning models for improved object classification

Cloud-based location monitoring for caregivers

Mobile application integration

Lightweight and energy-efficient hardware optimization

Support for multiple languages in speech feedback

ğŸ¤ Conclusion

BlindAssist successfully demonstrates how machine learning and embedded systems can be leveraged to create meaningful, real-world assistive technology. The project contributes toward improving independence, safety, and quality of life for visually impaired individuals.
